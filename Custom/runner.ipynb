{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e453c0",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/WholeNow/Garbage_Classifier/blob/main/Custom/Models/GarbageCustom_1.py\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2523e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Models\n",
    "from Models.GarbageCustom_1 import GC1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab3360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Percorsi e Dati\n",
    "    # Nota: Poiché lo script è in \"Custom Models/\", le immagini sono in \"../images\"\n",
    "    root_dir: str = '../images' \n",
    "    model_name: str = 'GC1'\n",
    "    \n",
    "    # Iperparametri\n",
    "    batch_size: int = 32\n",
    "    num_epochs: int = 50\n",
    "    val_epochs: int = 3\n",
    "    learning_rate: float = 0.001\n",
    "    \n",
    "    # Scheduler (Step Decay)\n",
    "    step_size: int = 10\n",
    "    gamma: float = 0.1\n",
    "    \n",
    "    # Split Dataset\n",
    "    val_split: float = 0.15   # 15% Validazione\n",
    "    test_split: float = 0.15  # 15% Test\n",
    "    \n",
    "    # Input GC1\n",
    "    img_size: int = 256\n",
    "    input_channels: int = 3\n",
    "    \n",
    "    # Sistema\n",
    "    seed: int = 42\n",
    "    num_workers: int = 0\n",
    "    device: str = \"auto\" # \"auto\", \"cuda\", \"mps\", \"cpu\"\n",
    "    checkpoint_path: str = \"garbage_custom_1_best.pth\"\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    print(f\"[INFO] Seed impostato: {seed}\")\n",
    "\n",
    "def get_device(device_pref: str = \"auto\"):\n",
    "    if device_pref != \"auto\":\n",
    "        return torch.device(device_pref)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"[INFO] Device: CUDA ({torch.cuda.get_device_name(0)})\")\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        print(\"[INFO] Device: MPS (Apple Silicon)\")\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        print(\"[INFO] Device: CPU\")\n",
    "        return torch.device(\"cpu\")\n",
    "    \n",
    "def get_model(model_name: str, input_channels: int, num_classes: int):\n",
    "    \"\"\"\n",
    "    Factory per il caricamento dinamico del modello.\n",
    "    \"\"\"\n",
    "    if model_name == \"GC1\":\n",
    "        # GC1 originale era hardcoded per 6 classi, lo adattiamo se necessario\n",
    "        # Se volete renderlo flessibile, modificate GC1 per prendere num_classes\n",
    "        # Per ora lo lascio come da richiesta originale, warning se mismatch\n",
    "        return GC1(input_size=input_channels)\n",
    "    else:\n",
    "        raise ValueError(f\"Modello '{model_name}' non riconosciuto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GarbageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        if not os.path.exists(root_dir):\n",
    "            # Fallback utile se lanciato da root invece che da Custom Models\n",
    "            if os.path.exists('images'):\n",
    "                 self.root_dir = 'images'\n",
    "            elif os.path.exists(os.path.join('..', 'images')):\n",
    "                 self.root_dir = os.path.join('..', 'images')\n",
    "            else:\n",
    "                 raise FileNotFoundError(f\"Directory {root_dir} non trovata.\")\n",
    "            \n",
    "        self.classes = sorted([d for d in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, d))])\n",
    "        \n",
    "        self.data = []\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.data.append((img_path, idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception:\n",
    "            raise Exception(f\"Impossibile aprire l'immagine: {img_path}\")\n",
    "            \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def get_targets(self):\n",
    "        return [label for _, label in self.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d82dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_stats(root_dir, img_size, batch_size=32, num_workers=0):\n",
    "    \"\"\"\n",
    "    Calcola la media e la deviazione standard del dataset.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Calcolo media e deviazione standard del dataset (può richiedere tempo)...\")\n",
    "    \n",
    "    # Dataset temporaneo senza normalizzazione\n",
    "    temp_transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    \n",
    "    dataset = GarbageDataset(root_dir, transform=temp_transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    \n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images_count = 0\n",
    "    \n",
    "    for images, _ in tqdm(loader, desc=\"Calcolo Stats\", leave=False):\n",
    "        batch_samples = images.size(0) # batch size (the last batch can have smaller size!)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    \n",
    "    print(f\"[INFO] Calcolato -> Mean: {mean.tolist()}, Std: {std.tolist()}\")\n",
    "    return mean.tolist(), std.tolist()\n",
    "\n",
    "def create_dataloaders(config):\n",
    "    # Calcolo dinamico di Mean e Std\n",
    "    # mean, std = get_dataset_stats(config.root_dir, config.img_size, config.batch_size, config.num_workers)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config.img_size, config.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.6582812666893005, 0.6344856023788452, 0.6075275540351868], std=[0.6582812666893005, 0.6344856023788452, 0.6075275540351868]) \n",
    "    ])\n",
    "\n",
    "    full_dataset = GarbageDataset(root_dir=config.root_dir, transform=transform)\n",
    "    config.num_classes = len(full_dataset.classes)\n",
    "    \n",
    "    targets = full_dataset.get_targets()\n",
    "    dataset_indices = list(range(len(full_dataset)))\n",
    "    \n",
    "    # Split 1: Test vs (Train+Val)\n",
    "    train_val_idx, test_idx = train_test_split(\n",
    "        dataset_indices, test_size=config.test_split, random_state=config.seed, stratify=targets\n",
    "    )\n",
    "    \n",
    "    # Split 2: Train vs Val\n",
    "    train_val_targets = [targets[i] for i in train_val_idx]\n",
    "    relative_val_split = config.val_split / (1.0 - config.test_split)\n",
    "    \n",
    "    train_idx, val_idx = train_test_split(\n",
    "        train_val_idx, test_size=relative_val_split, random_state=config.seed, stratify=train_val_targets\n",
    "    )\n",
    "\n",
    "    train_ds = Subset(full_dataset, train_idx)\n",
    "    val_ds = Subset(full_dataset, val_idx)\n",
    "    test_ds = Subset(full_dataset, test_idx)\n",
    "\n",
    "    print(f\"[INFO] Dati -> Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "    val_loader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "    test_loader = DataLoader(test_ds, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfa2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    set_seed(config.seed)\n",
    "    device = get_device(config.device)\n",
    "    \n",
    "    # 1. Dati\n",
    "    train_loader, val_loader, _ = create_dataloaders(config)\n",
    "    \n",
    "    # 2. Modello\n",
    "    print(f\"[TRAIN] Avvio training {config.model_name}...\")\n",
    "    \n",
    "    # Caricamento dinamico\n",
    "    try:\n",
    "        model = get_model(config.model_name, config.input_channels, config.num_classes).to(device)\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERRORE] {e}\")\n",
    "        return\n",
    "\n",
    "    # Config num_classes per sicurezza (aggiorna la FC se diverso da 6, ma qui GC1 è hardcoded a 6)\n",
    "    # Se volessimo renderlo dinamico, dovremmo cambiare GC1.__init__ per prendere num_classes\n",
    "    if config.num_classes != 6 and config.model_name == \"GC1\":\n",
    "        print(f\"[WARNING] Il modello è hardcoded per 6 classi, ma il dataset ne ha {config.num_classes}!\")\n",
    "    \n",
    "    # 3. Optimizer & Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Scheduler Step Decay\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    last_val_acc = 0.0\n",
    "    last_epoch = 0\n",
    "    last_best_path = \"\"\n",
    "    \n",
    "    try:\n",
    "        # ---------------------------------------------------\n",
    "        # LOOP DELLE EPOCHE\n",
    "        # ---------------------------------------------------\n",
    "        for epoch in range(1, config.num_epochs + 1):\n",
    "            \n",
    "            # --- TRAINING ---\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{config.num_epochs} [Train]\", leave=False)\n",
    "            \n",
    "            for inputs, labels in train_pbar:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item() * inputs.size(0)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                train_pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "            # Step dello scheduler alla fine dell'epoca\n",
    "            scheduler.step()\n",
    "                \n",
    "            avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "            avg_train_acc = 100 * train_correct / train_total\n",
    "\n",
    "            # --- VALIDATION ---\n",
    "            if epoch % config.val_epochs == 0:\n",
    "                model.eval()\n",
    "                val_loss = 0.0\n",
    "                val_correct = 0\n",
    "                val_total = 0\n",
    "\n",
    "                val_pbar = tqdm(val_loader, desc=f\"Epoch {epoch}/{config.num_epochs} [Val]\", leave=False)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for inputs, labels in val_pbar:\n",
    "                        inputs, labels = inputs.to(device), labels.to(device)\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        \n",
    "                        val_loss += loss.item() * inputs.size(0)\n",
    "                        _, predicted = torch.max(outputs, 1)\n",
    "                        val_total += labels.size(0)\n",
    "                        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                        val_pbar.set_postfix({'loss': loss.item()})\n",
    "                \n",
    "                avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "                avg_val_acc = 100 * val_correct / val_total\n",
    "\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                print(f\"Epoch {epoch} | LR: {current_lr:.6f} | Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.2f}% | Val Loss: {avg_val_loss:.4f} | Val Acc: {avg_val_acc:.2f}%\")\n",
    "            \n",
    "                if avg_val_acc > best_val_acc:\n",
    "                    best_val_acc = avg_val_acc\n",
    "\n",
    "                    if last_best_path:\n",
    "                        os.remove(last_best_path)\n",
    "\n",
    "                    checkpoint_path = config.checkpoint_path.replace(\".pth\", f\"_{avg_val_acc:.2f}_{epoch}.pth\")\n",
    "                    model.save_model(checkpoint_path, optimizer, avg_val_acc, epoch)\n",
    "                    print(f\"--> Best Model Saved (Acc: {best_val_acc:.2f}%) at {checkpoint_path}\")\n",
    "\n",
    "                    last_best_path = checkpoint_path\n",
    "\n",
    "                last_val_acc = avg_val_acc\n",
    "                last_epoch = epoch\n",
    "            else:\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                print(f\"Epoch {epoch} | LR: {current_lr:.6f} | Train Loss: {avg_train_loss:.4f} | Train Acc: {avg_train_acc:.2f}%\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "            print(\"\\n[TRAIN] Interrotto dall'utente (Ctrl+C).\")\n",
    "\n",
    "    model.save_model(config.checkpoint_path, optimizer, last_val_acc, last_epoch)\n",
    "    print(f\"--> Last Model Saved at {config.checkpoint_path}\")\n",
    "    print(\"[TRAIN] Completato.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    device = get_device(config.device)\n",
    "    \n",
    "    # 1. Dati\n",
    "    _, _, test_loader = create_dataloaders(config)\n",
    "    \n",
    "    # 2. Modello\n",
    "    print(f\"\\n[TEST] Avvio test modello salvato...\")\n",
    "    \n",
    "    try:\n",
    "        model = get_model(config.model_name, config.input_channels, config.num_classes).to(device)\n",
    "    except ValueError as e:\n",
    "        print(f\"[ERRORE] {e}\")\n",
    "        return\n",
    "    \n",
    "    # 3. Load Checkpoint\n",
    "    try:\n",
    "        model.load_model(config.checkpoint_path, device)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"[ERRORE] File checkpoint '{config.checkpoint_path}' non trovato.\")\n",
    "        return\n",
    "\n",
    "    # 4. Inference\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"[RESULT] Test Set Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc55631",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57d2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

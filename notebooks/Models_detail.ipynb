{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778290e2",
   "metadata": {},
   "source": [
    "# **GC1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc17999",
   "metadata": {},
   "source": [
    "Il modello GC1 ha la seguente struttura:\n",
    "\n",
    "#### conv1: First convolutional layer (dim -> 256x256x8)\n",
    "#### pool: First max pooling layer (dim -> 128x128x8)\n",
    "#### conv2: Second convolutional layer (dim -> 128x128x16)\n",
    "#### pool2: Second max pooling layer (dim -> 64x64x16)\n",
    "#### conv3: Third convolutional layer (dim -> 64x64x32)\n",
    "#### pool3: Third max pooling layer (dim -> 32x32x32)\n",
    "#### fc1: Fully connected layer (dim -> num_classes)\n",
    "#### softmax: Softmax layer (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d40127",
   "metadata": {},
   "source": [
    "### **Problemi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f97e5f",
   "metadata": {},
   "source": [
    "Overfitting: sale sul train ma sul validation si ferma a circa 65%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cf78d",
   "metadata": {},
   "source": [
    "### **Possibili soluzioni**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99601d15",
   "metadata": {},
   "source": [
    "- Aggiungere Dropout tra i layer completamente connessi\n",
    "- Utilizzare tecniche di regularization come L2 regularization\n",
    "- Sperimentare con diverse architetture di rete, come l'aggiunta di più layer convoluzionali o l'uso di architetture pre-addestrate (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fc4f8",
   "metadata": {},
   "source": [
    "# **GC2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb54dc",
   "metadata": {},
   "source": [
    "Il modello GC2 ha la seguente struttura:\n",
    "\n",
    "#### conv1: First convolutional layer (dim -> 256x256x12)\n",
    "#### conv2: Second convolutional layer (stride=2, kernel=5) (dim -> 126x126x16)\n",
    "#### pool: First max pooling layer (dim -> 63x63x16)\n",
    "#### conv3: Third convolutional layer (dim -> 63x63x24)\n",
    "#### conv4: Fourth convolutional layer (stride=2, kernel=5) (dim -> 30x30x32)\n",
    "#### pool2: Second max pooling layer (dim -> 15x15x32)\n",
    "#### fc1: Fully connected layer (dim -> 1024)\n",
    "#### dropout: Dropout layer (p=0.2)\n",
    "#### fc2: Output layer (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e825b",
   "metadata": {},
   "source": [
    "### **Modifiche rispetto a GC1**\n",
    "- Aumentato il numero di filtri iniziali (8→12) e aggiunto un quarto layer convoluzionale per maggiore capacità espressiva.\n",
    "- Riduzione della risoluzione tramite convoluzioni con stride=2 invece di soli max pooling, così da imparare anche la downsampling function.\n",
    "- Inserito layer fully-connected intermedio a 1024 neuroni prima dell'output finale (GC1 andava direttamente a num_classes).\n",
    "- Aggiunto dropout (p=0.2) tra i fully-connected per mitigare l'overfitting.\n",
    "- Output ora su fc2 dedicato invece di un unico fc finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac283a95",
   "metadata": {},
   "source": [
    "### **Problemi**\n",
    "- Train accuracy: 100%\n",
    "- Validation accuracy: 71.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0a439",
   "metadata": {},
   "source": [
    "### **Soluzioni**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e64c62",
   "metadata": {},
   "source": [
    "Per ridurre l'eccessivo overfitting e migliorare la generalizzazione del modello GC2, si potrebbero adottare le seguenti strategie:\n",
    "- **Aumentare il dropout**: Incrementare il tasso di dropout (ad esempio a 0.5) per ridurre ulteriormente la dipendenza del modello da specifici neuroni durante l'addestramento.\n",
    "- **Batch normalization**: Integrare layer di batch normalization dopo le convoluzioni per stabilizzare e accelerare l'addestramento.\n",
    "- **Kernel 3x3**: Sostituire i kernel 5x5 con kernel 3x3 per ridurre il numero di parametri e migliorare l'efficienza computazionale grazie allo stesso receptive field.\n",
    "- **Aumento della Profondità Convoluzionale**: Piuttosto che layer lineari enormi, più layer convoluzionali per estrarre feature di alto livello.\n",
    "- **Cambiare regolarizzazione**: Rimuovere la l1 regularization e sfruttare solo l2 dell'elastic net, per non perdere informazioni importanti portando a zero i pesi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981ea29",
   "metadata": {},
   "source": [
    "(l2 = 0.001, l1 = 0.000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

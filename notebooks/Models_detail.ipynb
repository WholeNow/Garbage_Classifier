{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778290e2",
   "metadata": {},
   "source": [
    "# **GC1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc17999",
   "metadata": {},
   "source": [
    "Il modello GC1 ha la seguente struttura:\n",
    "\n",
    "#### conv1: First convolutional layer (dim -> 256x256x8)\n",
    "#### pool: First max pooling layer (dim -> 128x128x8)\n",
    "#### conv2: Second convolutional layer (dim -> 128x128x16)\n",
    "#### pool2: Second max pooling layer (dim -> 64x64x16)\n",
    "#### conv3: Third convolutional layer (dim -> 64x64x32)\n",
    "#### pool3: Third max pooling layer (dim -> 32x32x32)\n",
    "#### fc1: Fully connected layer (dim -> num_classes)\n",
    "#### softmax: Softmax layer (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d40127",
   "metadata": {},
   "source": [
    "### **Problemi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f97e5f",
   "metadata": {},
   "source": [
    "Overfitting: sale sul train ma sul validation si ferma a circa 65%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48cf78d",
   "metadata": {},
   "source": [
    "### **Possibili soluzioni**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99601d15",
   "metadata": {},
   "source": [
    "- Aggiungere Dropout tra i layer completamente connessi\n",
    "- Utilizzare tecniche di regularization come L2 regularization\n",
    "- Sperimentare con diverse architetture di rete, come l'aggiunta di più layer convoluzionali o l'uso di architetture pre-addestrate (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fc4f8",
   "metadata": {},
   "source": [
    "# **GC2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb54dc",
   "metadata": {},
   "source": [
    "Il modello GC2 ha la seguente struttura:\n",
    "\n",
    "#### conv1: First convolutional layer (dim -> 256x256x12)\n",
    "#### conv2: Second convolutional layer (stride=2, kernel=5) (dim -> 126x126x16)\n",
    "#### pool: First max pooling layer (dim -> 63x63x16)\n",
    "#### conv3: Third convolutional layer (dim -> 63x63x24)\n",
    "#### conv4: Fourth convolutional layer (stride=2, kernel=5) (dim -> 30x30x32)\n",
    "#### pool2: Second max pooling layer (dim -> 15x15x32)\n",
    "#### fc1: Fully connected layer (dim -> 1024)\n",
    "#### dropout: Dropout layer (p=0.2)\n",
    "#### fc2: Output layer (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329e825b",
   "metadata": {},
   "source": [
    "### **Modifiche rispetto a GC1**\n",
    "- Aumentato il numero di filtri iniziali (8→12) e aggiunto un quarto layer convoluzionale per maggiore capacità espressiva.\n",
    "- Riduzione della risoluzione tramite convoluzioni con stride=2 invece di soli max pooling, così da imparare anche la downsampling function.\n",
    "- Inserito layer fully-connected intermedio a 1024 neuroni prima dell'output finale (GC1 andava direttamente a num_classes).\n",
    "- Aggiunto dropout (p=0.2) tra i fully-connected per mitigare l'overfitting.\n",
    "- Output ora su fc2 dedicato invece di un unico fc finale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac283a95",
   "metadata": {},
   "source": [
    "### **Problemi**\n",
    "- Train accuracy: 100%\n",
    "- Validation accuracy: 71.56%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0a439",
   "metadata": {},
   "source": [
    "### **Soluzioni**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e64c62",
   "metadata": {},
   "source": [
    "Per ridurre l'eccessivo overfitting e migliorare la generalizzazione del modello GC2, si potrebbero adottare le seguenti strategie:\n",
    "- **Aumentare il dropout**: Incrementare il tasso di dropout (ad esempio a 0.5) per ridurre ulteriormente la dipendenza del modello da specifici neuroni durante l'addestramento.\n",
    "- **Batch normalization**: Integrare layer di batch normalization dopo le convoluzioni per stabilizzare e accelerare l'addestramento.\n",
    "- **Kernel 3x3**: Sostituire i kernel 5x5 con kernel 3x3 per ridurre il numero di parametri e migliorare l'efficienza computazionale grazie allo stesso receptive field.\n",
    "- **Aumento della Profondità Convoluzionale**: Piuttosto che layer lineari enormi, più layer convoluzionali per estrarre feature di alto livello.\n",
    "- **Cambiare regolarizzazione**: Rimuovere la l1 regularization e sfruttare solo l2 dell'elastic net, per non perdere informazioni importanti portando a zero i pesi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b152579d",
   "metadata": {},
   "source": [
    "# **GC3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273354bb",
   "metadata": {},
   "source": [
    "Il modello GC3 ha la seguente struttura:\n",
    "\n",
    "#### conv1: First convolutional layer + batch normalization + ReLU (dim -> 256x256x16)\n",
    "#### conv2: Second convolutional layer (stride=2) + batch normalization + ReLU (dim -> 128x128x32)\n",
    "#### conv3: Third convolutional layer (stride=2) + batch normalization + ReLU (dim -> 64x64x64)\n",
    "#### pool: Max pooling layer (dim -> 32x32x64)\n",
    "#### conv4: Fourth convolutional layer (stride=2) + batch normalization + ReLU (dim -> 16x16x128)\n",
    "#### conv5: Fifth convolutional layer (stride=2) + batch normalization + ReLU (dim -> 8x8x128)\n",
    "#### conv6: Sixth convolutional layer (stride=2) + batch normalization + ReLU (dim -> 4x4x256)\n",
    "#### fc1: Fully connected layer (dim -> 1024)\n",
    "#### dropout: Dropout layer (p=0.5)\n",
    "#### fc2: Output layer (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea692db6",
   "metadata": {},
   "source": [
    "### **Modifiche rispetto a GC2**\n",
    "- Profondità aumentata (6 convolutional block stride-based) con mappe 16→32→64→128→128→256 per una rappresentazione più ricca.\n",
    "- Batch normalization dopo ogni convoluzione per stabilizzare l'ottimizzazione e ridurre la covariate shift.\n",
    "- Downsampling quasi interamente tramite stride nelle convoluzioni invece che con max pooling ripetuti, così da imparare la funzione di riduzione.\n",
    "- Dropout innalzato a 0.5 sul fully connected da 1024 neuroni per contenere l'overfitting.\n",
    "- Regolarizzazione elastica semplificata: l1 disattivata (l1_alpha=0) e mantenuta solo l2 (0.0008)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccb038c",
   "metadata": {},
   "source": [
    "### **Risultati**\n",
    "- Accuratezza di validazione massima: **78.99%** all'epoca 35 (checkpoint: [Results/GC3/garbage_custom_3_best_78.99_35.pth](Results/GC3/garbage_custom_3_best_78.99_35.pth)).\n",
    "- +7.4 punti circa rispetto al best di GC2 (71.56%).\n",
    "- La curva di validation è più stabile ma resta un divario con il training, segno di overfitting residuo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e4e6d",
   "metadata": {},
   "source": [
    "### **Problemi**\n",
    "- Overfitting ancora presente: la curva di training resta sopra quella di validation.\n",
    "- Val accuracy si assesta sotto l'80%, suggerendo margine di generalizzazione non sfruttato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9844b05b",
   "metadata": {},
   "source": [
    "### **Possibili miglioramenti**\n",
    "- Aumentare l'augmentazione (color jitter, cutout/mixup) per spingere la generalizzazione oltre il 79%.\n",
    "- Introdurre label smoothing (ε≈0.05-0.1) e un leggero weight decay per regolarizzare ulteriormente.\n",
    "- Testare scheduler più dolci (cosine annealing + warmup) per evitare plateau precoce della val_loss.\n",
    "- Sperimentare skip/residual connection leggere o ridurre gli stride iniziali per non perdere dettagli di texture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038df34",
   "metadata": {},
   "source": [
    "# **GC4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe989288",
   "metadata": {},
   "source": [
    "Il modello GC4 ha la seguente struttura:\n",
    "\n",
    "#### conv1: 3x3 conv + batch norm + ReLU (dim -> 256x256x32)\n",
    "#### resblock1: Tre conv 3x3 con batch norm e skip connection (dim -> 256x256x32)\n",
    "#### conv2: 3x3 conv stride=3 + batch norm + ReLU (dim -> 86x86x64)\n",
    "#### resblock2: Tre conv 3x3 con batch norm e skip connection (dim -> 86x86x64)\n",
    "#### conv3: 3x3 conv stride=3, padding=2 + batch norm + ReLU (dim -> 30x30x128)\n",
    "#### resblock3: Tre conv 3x3 con batch norm e skip connection (dim -> 30x30x128)\n",
    "#### pool: MaxPool 2x2 stride=2 (dim -> 15x15x128)\n",
    "#### conv4: 3x3 conv stride=2 + batch norm + ReLU (dim -> 8x8x256)\n",
    "#### conv5: 3x3 conv stride=1 + batch norm + ReLU (dim -> 8x8x512)\n",
    "#### global_avg_pool: AdaptiveAvgPool2d(1) (dim -> 1x1x512)\n",
    "#### dropout: p=0.3\n",
    "#### fc: Fully connected (dim -> num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763483e6",
   "metadata": {},
   "source": [
    "### **Modifiche rispetto a GC3**\n",
    "- Inserite tre residual block (3x3) per canale 32/64/128 con skip identity, così da stabilizzare il deepening e mantenere le feature locali.\n",
    "- Downsampling più aggressivo con stride=3 nelle prime due fasi (256→86→30) per comprimere rapidamente la risoluzione e ridurre il costo computazionale.\n",
    "- Canali ampliati fino a 512 prima del classifier e passaggio a global average pooling per eliminare i fully-connected flattenati.\n",
    "- Dropout moderato (0.3) invece di 0.5 e weight init Kaiming su conv/linear.\n",
    "- Validazione più rigida sull'input: il forward lancia errori se la shape non è (N, 3, 256, 256)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a74fe82",
   "metadata": {},
   "source": [
    "### **Risultati**\n",
    "- Accuratezza di validazione massima: **83.26%** all'epoca 50 (checkpoint: [Results/GC4/garbage_custom_4_best_83.26_50.pth](Results/GC4/garbage_custom_4_best_83.26_50.pth)).\n",
    "- Train accuracy finale intorno al 95-96%, con un gap più contenuto rispetto a GC3.\n",
    "- La validation accuracy cresce in modo costante fino a ~83% e si appiattisce dopo l'epoca ~45.\n",
    "- Val loss: ~11→~0.7; Train loss: ~6.5→~1.1 (curve stabili dopo metà training).\n",
    "- Guadagno di circa +4.3 punti rispetto al best di GC3 (78.99%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a76492",
   "metadata": {},
   "source": [
    "### **Problemi**\n",
    "- Overfitting ancora presente: il train resta ~10-12 punti sopra la validation.\n",
    "- Downsampling con stride=3 nelle prime fasi rischia di perdere texture sottili (vetro/plastica).\n",
    "- Curva di validation si stabilizza presto: il scheduler corrente non spinge oltre l'83% pur con loss in calo lenta.\n",
    "- Troppi layer convoluzionali e batch normalization potrebbero aver aumentato la complessità senza migliorare la generalizzazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34dd414",
   "metadata": {},
   "source": [
    "### **Possibili miglioramenti**\n",
    "- Aumentare leggeremente il dropout (0.4) o sperimentare stochastic depth sui residual block per regolarizzare.\n",
    "- Provare a cambiare la regolarizzazione (weight decay)\n",
    "- Ridurre il numero di layer della rete per diminuire l'overfitting.\n",
    "- Sperimentare con scheduler più aggressivi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c04734",
   "metadata": {},
   "source": [
    "# **GC5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc064d6f",
   "metadata": {},
   "source": [
    "Il modello GC5 ha la seguente struttura:\n",
    "\n",
    "#### conv1: 3x3 conv (in=3, out=4) + ReLU (dim -> 256x256x4)\n",
    "#### pool1: AvgPool2d 2x2 stride=2 (dim -> 128x128x4)\n",
    "#### resblock1: Residual block con canali 4→12 e identity adattata (dim -> 128x128x12)\n",
    "#### pool2: AvgPool2d 2x2 stride=2 (dim -> 64x64x12)\n",
    "#### resblock2: Residual block con canali 12→36 (dim -> 64x64x36)\n",
    "#### pool3: AvgPool2d 2x2 stride=2 (dim -> 32x32x36)\n",
    "#### resblock3: Residual block con canali 36→108 (dim -> 32x32x108)\n",
    "#### pool4: AvgPool2d 2x2 stride=2 (dim -> 16x16x108)\n",
    "#### resblock4: Residual block con canali 108→324 (dim -> 16x16x324)\n",
    "#### pool5: AvgPool2d 2x2 stride=2 (dim -> 8x8x324)\n",
    "#### conv2: 4x4 conv stride=2 pad=1 (dim -> 4x4x512) + ReLU\n",
    "#### global_avg_pool: AdaptiveAvgPool2d(1) (dim -> 1x1x512)\n",
    "#### dropout: p=0.5\n",
    "#### fc: Fully connected (dim -> num_classes)\n",
    "#### shape check: il forward valida (N, 3, 256, 256) e solleva errori se diverso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7345478",
   "metadata": {},
   "source": [
    "### **Modifiche rispetto a GC4**\n",
    "- Stem molto più stretto (4 canali iniziali) e downsampling via average pooling: meno parametri e inferenza più leggera.\n",
    "- Residual block con identity adattata che ampliano progressivamente i canali (4→12→36→108→324) mantenendo stabilità in training.\n",
    "- Head compatta: una sola conv finale a 512 canali + global average pooling + dropout 0.5, senza fully-connected estesi.\n",
    "- Input validation esplicita nel forward per evitare errori di shape.\n",
    "- Regolarizzazione più decisa lato weight decay (l2_alpha=0.0012) e learning rate ridotto (3e-4)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b55dc9",
   "metadata": {},
   "source": [
    "### **Risultati**\n",
    "- Accuratezza di validazione massima: **85.61%** intorno all'epoca 45 (checkpoint: [Results/GC5/garbage_custom_1_best_85.61_45.pth](Results/GC5/garbage_custom_1_best_85.61_45.pth)).\n",
    "- Curva di validation accuracy sale rapidamente a ~83% (epoca ~20) e si stabilizza verso 85% con oscillazioni minime; train accuracy ≈95%.\n",
    "- Loss in calo regolare: train da ~6.2→~1.0, validation da ~1.1→~0.45, senza divergenze nella fase finale.\n",
    "- +2.35 punti circa rispetto al best di GC4 (83.26%) con modello più leggero e tempi di training/inferenza ridotti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622751da",
   "metadata": {},
   "source": [
    "### **Analisi finale**\n",
    "- GC5 è il modello finale: migliore accuratezza validazione (+2.35 pt su GC4) e architettura più leggera grazie allo stem ridotto e al GAP senza fully-connected pesanti.\n",
    "- Il gap train/val è contenuto (≈10 pt) e le curve sono stabili: rischio di overfitting residuo ma sotto controllo.\n",
    "- Consigliato come default per produzione: input 256x256 RGB, lr 3e-4, l2=0.0012, dropout 0.5.\n",
    "- Possibili micro-migliorie: augmentazione aggiuntiva su classi minoritarie, label smoothing leggero, valutare quantizzazione post-training per ulteriore velocità."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
